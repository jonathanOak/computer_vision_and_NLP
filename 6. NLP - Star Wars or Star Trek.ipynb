{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# you can visit the deployed model here\n",
    "## https://beyond-far-away.herokuapp.com\n",
    "\n",
    "### It takes a few seconds to load >.<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional,Flatten,Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset with lines from start wars and star trek movies\n",
    "df = pd.read_csv('wars_trek_random.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change data type to avoid conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Input'] = df['Input'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        turmoil has engulfed the galactic republic the...\n",
       "1                     outlaying star systems is in dispute\n",
       "2        hoping to resolve the matter with a blockade o...\n",
       "3        greedy trade federation has stopped all shippi...\n",
       "4                                                    naboo\n",
       "                               ...                        \n",
       "18068                       new civilizations to boldly go\n",
       "18069                         where no man has gone before\n",
       "18070     she is moving out now passing camera and heading\n",
       "18071    toward the distant stars she is beautiful and ...\n",
       "18072    are beautiful and as she slowly disappears fro...\n",
       "Name: clean, Length: 18073, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = df['Input'].apply(lambda x: remove_punctuation(x))\n",
    "df['clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer1 = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [turmoil, has, engulfed, the, galactic, republ...\n",
       "1              [outlaying, star, systems, is, in, dispute]\n",
       "2        [hoping, to, resolve, the, matter, with, a, bl...\n",
       "3        [greedy, trade, federation, has, stopped, all,...\n",
       "4                                                  [naboo]\n",
       "                               ...                        \n",
       "18068                 [new, civilizations, to, boldly, go]\n",
       "18069                  [where, no, man, has, gone, before]\n",
       "18070    [she, is, moving, out, now, passing, camera, a...\n",
       "18071    [toward, the, distant, stars, she, is, beautif...\n",
       "18072    [are, beautiful, and, as, she, slowly, disappe...\n",
       "Name: clean, Length: 18073, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = df['clean'].apply(lambda x: tokenizer1.tokenize(x.lower()))\n",
    "df['clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000,lower=True,split=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df['Input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(df['Input'])\n",
    "X = pad_sequences(X,maxlen=500)\n",
    "Y = df['Value']\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, X_test, y, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, Y_train, Y_eval = train_test_split(x, y, test_size=0.1, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 50)           82900     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               183296    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 266,453\n",
      "Trainable params: 266,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=500)) \n",
    "model.add(Bidirectional(LSTM(128))) #number of batches\n",
    "model.add(Dropout(0.5)) #randomily removing some of the neurons from the architecture to decrease overfiting\n",
    "model.add(Dense(1,activation='sigmoid')) #it regulates the outputs \n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy']) #regulate dropout\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, Y_train, batch_size=128, epochs=4, validation_data=[X_test, Y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_eval, Y_eval, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('stars15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('stars15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars with 99.99% confidence\n",
      "Star Trek with 99.90% confidence\n",
      "Star Wars with 99.60% confidence\n",
      "Star Trek with 99.75% confidence\n",
      "Star Wars with 99.95% confidence\n"
     ]
    }
   ],
   "source": [
    "lst = [\n",
    "    'may the force be with you',\n",
    "    'beam me up scotty',\n",
    "    'do or do not there is no try',\n",
    "    'logic is the beginning of wisdom not the end',\n",
    "    'never tell me the odds'\n",
    "]\n",
    "for i in lst:\n",
    "    \n",
    "    x_2=tokenizer.texts_to_sequences([i])\n",
    "    x_2 = pad_sequences(x_2,maxlen=500)\n",
    "    prediction = model.predict(x_2)[0][0]\n",
    "\n",
    "    if prediction > 0.6:\n",
    "        print('Star Wars with {:.2f}% confidence'.format(prediction*100))\n",
    "    elif prediction < 0.4:\n",
    "        print('Star Trek with {:.2f}% confidence'.format((1-prediction)*100))\n",
    "    else:\n",
    "        print('Not sure!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
